{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from torch import nn  #导入神经网络模块\n",
    "from torch.utils.data import DataLoader  #数据包管理工具，打包数据\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import time\n",
    "\n",
    "#from torchvision import  datasets  #封装了很多与图像相关的模型，数据集\n",
    "\n",
    "'''检查 CUDA 是否可用，并设置设备（\"cuda:0\" 或 \"cpu\"）'''\n",
    "print(\"PyTorch 版本：\", torch.__version__)  # 打印 PyTorch 的版本号\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"设备：\", device)  # 打印当前使用的设备\n",
    "print(\"CUDA 可用：\", torch.cuda.is_available())  # 打印 CUDA 是否可用\n",
    "print(\"cuDNN 已启用：\", torch.backends.cudnn.enabled)  # 打印 cuDNN 是否已启用\n",
    "print(\"支持的 CUDA 版本：\", torch.version.cuda)\n",
    "print(\"cuDNN 版本：\", torch.backends.cudnn.version())\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): 数据集的根目录\n",
    "            transform (callable, optional): 可选的图像变换\n",
    "            标签为图片文件名的首字母，图片为bmp格式\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 收集所有图像路径和对应的标签（文件名的首字母）\n",
    "        self.samples = []\n",
    "        self.labels_set = set()  # 用于收集所有独特的标签\n",
    "\n",
    "        # 遍历根目录下的所有bmp文件\n",
    "        for img_name in os.listdir(root_dir):\n",
    "            img_path = os.path.join(root_dir, img_name)\n",
    "            if os.path.isfile(img_path) and img_name.lower().endswith('.bmp'):\n",
    "                # 获取文件名的首字母作为标签\n",
    "                first_letter = img_name[0].upper()  # 转换为大写以确保一致性\n",
    "                self.samples.append((img_path, first_letter))\n",
    "                self.labels_set.add(first_letter)\n",
    "\n",
    "        # 创建标签到索引的映射\n",
    "        self.classes = sorted(list(self.labels_set))\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "\n",
    "        # 更新samples中的标签为索引形式\n",
    "        self.samples = [(img_path, self.class_to_idx[label]) for img_path, label in self.samples]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label_idx = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label_idx\n",
    "\n",
    "    def get_original_label(self, idx):\n",
    "        \"\"\"获取原始的首字母标签（字符串形式）\"\"\"\n",
    "        img_path, label_idx = self.samples[idx]\n",
    "        # 通过索引反向查找标签字符串\n",
    "        for label, index in self.class_to_idx.items():\n",
    "            if index == label_idx:\n",
    "                return label\n",
    "        return None\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),  # 统一尺寸\n",
    "    transforms.Grayscale(),  # 转为灰度（如果是彩色BMP）\n",
    "    transforms.ToTensor(),  # 必须的\n",
    "    #transforms.Normalize((0.1307,), (0.3081,))  # 可选，可以先注释掉\n",
    "])\n",
    "batch_size = 200\n",
    "# 创建数据集\n",
    "dataset = MyDataset(root_dir='data/1-Digit-TrainSet/TrainingSet', transform=transform)\n",
    "#dataset = MyDataset(root_dir='data/1-Digit-TestSet/TestSet', transform=transform)\n",
    "# 打印数据集信息\n",
    "print(f\"数据集大小: {len(dataset)}\")\n",
    "print(f\"所有标签: {dataset.classes}\")\n",
    "print(f\"标签映射: {dataset.class_to_idx}\")\n",
    "\n",
    "# 创建数据加载器\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "print(\"完成\")\n",
    "'''dataloader检查 必须num_workers=0'''\n",
    "for images, labels in dataloader:\n",
    "    print(f\"图像形状: {images.shape}\")\n",
    "    print(f\"标签: {labels}\")\n",
    "    break\n",
    "\n",
    "# 获取原始标签示例\n",
    "if len(dataset) > 0:\n",
    "    original_label = dataset.get_original_label(0)\n",
    "    print(f\"第一个样本的原始标签: {original_label}\")\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # 使用padding=2来保持尺寸\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3, stride=1, padding=1)\n",
    "        # 这样特征图尺寸就是 20 * 7 * 7\n",
    "        self.fc1 = nn.Linear(20 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))  # 28x28 -> 28x28 (padding=2保持尺寸)\n",
    "        x = torch.max_pool2d(x, 2)  # 28x28 -> 14x14\n",
    "        x = torch.relu(self.conv2(x))  # 14x14 -> 14x14\n",
    "        x = torch.max_pool2d(x, 2)  # 14x14 -> 7x7\n",
    "\n",
    "        x = x.view(-1, 20 * 7 * 7)  # 展平\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 创建模型实例\n",
    "if torch.cuda.is_available() == 1:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CNN is running on GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CNN is running on CPU\")\n",
    "model = SimpleCNN().to(device)  #把刚刚创建的模型传入到GPU\n",
    "\n",
    "print(model)\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()  #告诉模型，我要开始训练，模型中w进行随机化操作，已经更新w，在训练过程中，w会被修改的\n",
    "    # pytorch提供2种方式来切换训练和测试的模式，分别是：model.train() 和 mdoel.eval()\n",
    "    # 一般用法是：在训练开始之前写上model.train(),在测试时写上model.eval()\n",
    "    batch_size_num = 1\n",
    "    for X, y in dataloader:  #其中batch为每一个数据的编号\n",
    "        X, y = X.to(device), y.to(device)  #把训练数据集和标签传入cpu或GPU\n",
    "        pred = model.forward(X)  # .forward可以被省略，父类种已经对此功能进行了设置\n",
    "        loss = loss_fn(pred, y)  # 通过交叉熵损失函数计算损失值loss\n",
    "        # Backpropagation 进来一个batch的数据，计算一次梯度，更新一次网络\n",
    "        optimizer.zero_grad()  # 梯度值清零\n",
    "        loss.backward()  # 反向传播计算得到每个参数的梯度值w\n",
    "        optimizer.step()  # 根据梯度更新网络w参数\n",
    "\n",
    "        loss_value = loss.item()  # 从tensor数据种提取数据出来，tensor获取损失值\n",
    "        if batch_size_num % 100 == 0:\n",
    "            print(f\"loss: {loss_value:>7f} [number:{batch_size_num}]\")\n",
    "        batch_size_num += 1\n",
    "\n",
    "\n",
    "def Test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)  #10000\n",
    "    num_batches = len(dataloader)  # 打包的数量\n",
    "    model.eval()  #测试，w就不能再更新\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():  #一个上下文管理器，关闭梯度计算。当你确认不会调用Tensor.backward()的时候\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model.forward(X)\n",
    "            test_loss += loss_fn(pred, y).item()  #test_loss是会自动累加每一个批次的损失值\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            a = (pred.argmax(1) == y)  #dim=1表示每一行中的最大值对应的索引号，dim=0表示每一列中的最大值对应的索引号\n",
    "            b = (pred.argmax(1) == y).type(torch.float)\n",
    "    test_loss /= num_batches  #能来衡量模型测试的好坏\n",
    "    correct /= size  #平均的正确率\n",
    "    print(f\"Test result: \\n Accuracy:{(100 * correct)}%, Avg loss:{test_loss}\")\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()  #创建交叉熵损失函数对象，因为手写字识别一共有十种数字，输出会有10个结果\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  #创建一个优化器\n",
    "#train(dataloader,model,loss_fn,optimizer)\n",
    "#Test(test_dataloader,model,loss_fn)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "test_dataset = MyDataset(root_dir='data/1-Digit-TestSet/TestSet', transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"epoch {t + 1}\\n---------------\")\n",
    "    train(dataloader, model, loss_fn, optimizer)  #训练1次完整的数据。多轮训练\n",
    "    Test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n",
    "test_dataset = MyDataset(root_dir='data/1-Digit-TestSet/TestSet', transform=transform)\n",
    "# 打印数据集信息\n",
    "print(f\"数据集大小: {len(test_dataset)}\")\n",
    "print(f\"所有标签: {test_dataset.classes}\")\n",
    "print(f\"标签映射: {test_dataset.class_to_idx}\")\n",
    "\n",
    "# 创建数据加载器\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "print(\"完成\")\n",
    "Test(test_dataloader, model, loss_fn)"
   ],
   "id": "5749445f8a2a9ecd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
